# -*- coding: utf-8 -*-
"""Locb1607000

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qOKlwWuUec8DaYpoDyDhMq3aW78dDEpE

**Import** **library**
"""

!pip install pysrt
!pip install ffmpeg-python
from keras.models import load_model
from sklearn.model_selection import train_test_split
import subprocess
import librosa
import pysrt
import re
import numpy as np
import pickle
import os
import time
import sys
import math
from sklearn import metrics
import collections
from keras.models import Sequential
from keras.layers import Dense, Input, LSTM, Conv1D, Conv2D, Dropout, Flatten, Activation, MaxPooling2D
from keras.models import Model
from keras.layers.normalization import BatchNormalization
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.optimizers import Adam, RMSprop
import matplotlib as plt
import librosa.display
from keras.models import load_model
import matplotlib.pylab as plt
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import confusion_matrix
from datetime import datetime, timedelta
from functools import reduce
from sklearn.metrics import accuracy_score
# np.set_printoptions(threshold=sys.maxsize)

"""**Cấu trúc thư mục**"""

TRAIN1_DATA_DIR = '../content/drive/My Drive/LuanVan_B1607000/Datasets/Khmer-Khmer/Train/'
TEST1_DATA_DIR = '../content/drive/My Drive/LuanVan_B1607000/Datasets/Khmer-Khmer/Test/'

TRAIN2_DATA_DIR = '../content/drive/My Drive/LuanVan_B1607000/Datasets/Khmer-Viet/Train/'
TEST2_DATA_DIR = '../content/drive/My Drive/LuanVan_B1607000/Datasets/Khmer-Viet/Test/'

TRAIN3_DATA_DIR = '../content/drive/My Drive/LuanVan_B1607000/Datasets/Khmer+Viet-Khmer/Train/'
TEST3_DATA_DIR = '../content/drive/My Drive/LuanVan_B1607000/Datasets/Khmer+Viet-Khmer/Test/'

TRAIN_STORE_DIR = '../content/drive/My Drive/LuanVan_B1607000/Store_Train_File/'

RNN1_MODEL_STORE = '../content/drive/My Drive/LuanVan_B1607000/models/Khmer-Khmer/RNN/'
CNN1_MODEL_STORE = '../content/drive/My Drive/LuanVan_B1607000/models/Khmer-Khmer/CNN/'

RNN2_MODEL_STORE = '../content/drive/My Drive/LuanVan_B1607000/models/Khmer-Viet/RNN/'
CNN2_MODEL_STORE = '../content/drive/My Drive/LuanVan_B1607000/models/Khmer-Viet/CNN/'

RNN3_MODEL_STORE = '../content/drive/My Drive/LuanVan_B1607000/models/Khmer+Viet-Khmer/RNN/'
CNN3_MODEL_STORE = '../content/drive/My Drive/LuanVan_B1607000/models/Khmer+Viet-Khmer/CNN/'

RESULT1_DIR = '../content/drive/My Drive/LuanVan_B1607000/Result/srt-predict/Khmer-Khmer/'
RESULT2_DIR = '../content/drive/My Drive/LuanVan_B1607000/Result/srt-predict/Khmer-Viet/'
RESULT3_DIR = '../content/drive/My Drive/LuanVan_B1607000/Result/srt-predict/Khmer+Viet-Khmer/'

"""**Phân khung và chia mẫu**"""

def get_len_mfcc(len_sample, hop_len, freq):
    return len_sample/(hop_len/freq)

def get_step_mfcc(step_sample, hop_len, freq):
    return step_sample/(hop_len/freq)

# Convert timestamp to seconds
def timeToSec(t):
    total_sec = float(t.milliseconds)/1000
    total_sec += t.seconds
    total_sec += t.minutes*60
    total_sec += t.hours*60*60    
    return total_sec

def secToTime(t):
  return "%02d:%02d:%02d.%03d" % \
    reduce(lambda ll,b : divmod(ll[0],b) + ll[1:],
      [(round(t*1000),),1000,60,60])

# Return timestamp from cell position
def timeToPos(t, step_mfcc, freq, hop_len):
    return int((float(freq * timeToSec(t)) / hop_len) / step_mfcc)
 
# Return seconds from cell position
def secToPos(t, step_mfcc, freq, hop_len):
    return int((float(freq*t)/hop_len)/step_mfcc)

# Return cell position from timestamp
def posToTime(pos, step_mfcc, freq, hop_len):
    return float(pos)*step_mfcc*hop_len/freq

"""**Generate Dataset**"""

# Stores the audio extracted from audio_files and returns its name_files
def getAudio(freq, dir, audio_files=None):
    files = os.listdir(dir)
    p = re.compile('.*\.[mp4]')
    files = [ f for f in files if p.match(f) ]
    if audio_files:
        files = [ f for f in files if os.path.splitext(f)[0] in audio_files]
    audio_dirs = []
    for f in files:
        name, extension = os.path.splitext(f)
        if extension == '.mp4':
          subprocess.call(
                  ['ffmpeg', '-i', dir + f, '-ab', '160k','-ac','2','-ar', '16000', '-vn', dir + name + '.wav'])
          audio_dirs.append(dir + name + '.wav')
    return audio_dirs
    
def file_name(dir):
    file_name = []
    files = os.listdir(dir)
    for file in files:
        name, extension = os.path.splitext(file)
        if extension == '.mp4':
            file_name.append(file.replace(extension, ''))
    return file_name

# Generate a train dataset from a video file and its subtitles
def generateSingleDataset(train_file, cut_data, len_mfcc, step_mfcc, hop_len, freq, dir, verbose=True):
    if verbose: print('Loading', train_file, 'data...')
  
    total_time = time.time()
    
    # Process audio
    t = time.time()
    audio_dir = getAudio(freq,dir, train_file)
    t_audio = time.time()-t
    if verbose: print("- Audio extracted: {0:02d}:{1:02d}".format(int(t_audio/60), int(t_audio % 60)))

    # Load subtitles
    subs = pysrt.open(dir+ train_file + '.srt')
    
    t = time.time()
    if cut_data:
        # Def audio starting and ending point
        start = timeToSec(subs[0].start)-2
        start = start if start>0 else 0
        subs.shift(seconds=-start)
        
        # Load audio file
        for i in audio_dir:
          y, sr = librosa.load(i, sr=freq, offset=start)#, duration=end)
    else:
        # Load audio file
          y, sr = librosa.load(audio_dir[0], sr=freq)
    # Remove audio from disk
    for i in audio_dir:
      os.remove(i)
    
    t_audio_load = time.time()-t
    if verbose: print("- Audio loaded: {0:02d}:{1:02d}".format(int(t_audio_load/60), int(t_audio_load % 60)))

    t = time.time()
    # Get MFCC features
    mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=int(hop_len), n_mfcc=13)
    if len_mfcc == 1 and step_mfcc == 1:   
        samples = mfcc.T
        train_data = np.stack(samples)      
    else:
        samples = []
        for i in np.arange(0, mfcc.shape[1], step_mfcc):
            samples.append(mfcc[:,int(i):int(i)+int(len_mfcc)])
            
        # Remove last element. Probably not complete
        samples = samples[:int((mfcc.shape[1]-len_mfcc)/step_mfcc)+1]
        train_data = np.stack(samples) 
        
    t_feat = time.time()-t
    if verbose: print("- Features calculated: {0:02d}:{1:02d}".format(int(t_feat/60), int(t_feat % 60)))
    t = time.time()
        # Create array of labels
    labels = np.zeros(len(train_data))
    for sub in subs:
        for i in np.arange(timeToPos(sub.start, step_mfcc, freq, hop_len), timeToPos(sub.end, step_mfcc, freq, hop_len)+1):
            if i < len(labels):
                labels[i] = 1        
    t_labels = time.time()-t
    if verbose: print("- Labels calculated: {0:02d}:{1:02d}".format(int(t_labels/60), int(t_labels % 60)))
    total_time = time.time()-total_time
    if verbose: print('Data times. audio: {0:.2f}, audio_load {1:.2f}, t_feat: {2:.2f},  t_labels {3:.2f}, total_time: {4:.2f},train_data_shape: {5}'.format(t_audio, t_audio_load, t_feat, t_labels, total_time, str(train_data.shape)))
    
    if verbose: print('\nTrain data shape: ',train_data.shape,'\nLabel shape:', labels.shape)
    return train_data, labels
    
    
# Generate a train dataset from an array of video files
def generateDatasets(train_files, cut_data, len_mfcc, step_mfcc, hop_len, freq, dir,model):
    
    X, Y = [], []
    
    for tf in train_files:
        train_data, labels = generateSingleDataset(tf, cut_data, len_mfcc, step_mfcc, hop_len, freq, dir)
        X.append(train_data)
        Y.append(labels)
    X = np.concatenate(X)
    Y = np.concatenate(Y)
    if cut_data:
      if model=='RNN':
        filename = TRAIN_STORE_DIR + model + '/dataset_CUT_' + str(freq) + '_' + str(hop_len) + '_' + str(len_mfcc) + '_' + str(step_mfcc) + '_' + str(X.shape[0]) + '_' + str(X.shape[1]) + '_' + str(X.shape[2]) + '.pickle'
      if model=="CNN":
        filename = TRAIN_STORE_DIR + model + '/dataset_CUT_' + str(freq) + '_' + str(hop_len) + '_' + str(len_mfcc) + '_' + str(step_mfcc) + '_' + str(train_data.shape[0]) + '_' + str(X.shape[1]) + '.pickle'
    else:
      if model=='RNN':
        filename = TRAIN_STORE_DIR + model + '/dataset_' + str(freq) + '_' + str(hop_len) + '_' + str(len_mfcc) + '_' + str(step_mfcc) + '_' + str(X.shape[0]) + '_' + str(X.shape[1]) + '_' + str(X.shape[2]) + '.pickle'
      if model=="CNN":
        filename = TRAIN_STORE_DIR + model + '/dataset_' + str(freq) + '_' + str(hop_len) + '_' + str(len_mfcc) + '_' + str(step_mfcc) + '_' + str(X.shape[0]) + '_' + str(X.shape[1]) + '.pickle'
    with open(filename, 'wb') as f:
        pickle.dump([X, Y], f)
    return X, Y

"""**Xây dựng mô hình**"""

def model_lstm(input_shape):
    inp = Input(shape=input_shape)
    model = inp
    if input_shape[0] > 2: model = Conv1D(filters=24, kernel_size=(3), activation='relu')(model)
    model = LSTM(16)(model)
    model = Activation('relu')(model)
    model = Dropout(0.2)(model)
    model = Dense(16)(model)
    model = Activation('relu')(model)
    model = BatchNormalization()(model)
    model = Dense(1)(model)
    model = Activation('sigmoid')(model)   
    model = Model(inp, model)
    return model
    
# Conv-1D architecture. Just one sample as input
def model_dense(input_shape):
    inp = Input(shape=input_shape)
    model = inp   
    model = Conv1D(filters=12, kernel_size=(3), activation='relu')(model)
    model = Conv1D(filters=12, kernel_size=(3), activation='relu')(model)
    model = Flatten()(model)
    model = Dense(56)(model)
    model = Activation('relu')(model)
    model = BatchNormalization()(model)
    model = Dropout(0.2)(model)
    model = Dense(28)(model)
    model = Activation('relu')(model)
    model = BatchNormalization()(model)
    model = Dense(1)(model)
    model = Activation('sigmoid')(model)   
    model = Model(inp, model)
    return model

"""**Train RNN**"""

def train_lstm(dir_train_file, dir_model_save):   
    t = time.time()
    nn = model_lstm
    step_sample = 0.05    # overlap mỗi mẫu 50ms  
    train_files = file_name(dir_train_file)
    for len_sample in [0.25]: #độ dài thời gian mẫu 0.25s
        for f in [16000]:
            for hop_len in [256.0,512.0,1024.0]:
                print('FREQ:', f, hop_len, len_sample)                
                t = time.time()
             
                len_mfcc = get_len_mfcc(len_sample, hop_len, f)    
                step_mfcc = get_step_mfcc(step_sample, hop_len, f)     
                print('len_mfcc',len_mfcc)
                print('step_mfcc',step_mfcc)
                X, Y = generateDatasets(train_files, True, len_mfcc, step_mfcc, hop_len=hop_len, freq=f, dir = dir_train_file, model = "RNN")
                
                rand = np.random.permutation(np.arange(len(Y)))
                X = X[rand]
                Y = Y[rand]
                X = np.array([ np.rot90(val) for val in X ])
                X = X - np.mean(X, axis=0)
            
                print('\nTrain data shape: ', X.shape,'\nNumber of label 0: ', len(Y[Y==0]),'\nNumber of label 1:', len(Y[Y==1]), float(len(Y[Y==0]))/len(Y[Y==1]))
                
                if X.shape[1] == 0:
                    print("NEXT\n")
                    continue
                input_shape = (X.shape[1], X.shape[2]) 
                model = nn(input_shape)            
                earlyStopping = EarlyStopping(monitor='val_loss', min_delta=0.00001, verbose=0, mode='min', patience=5)
                filename = dir_model_save + '/model_RNN_' + str(f) + '_' + str(len_mfcc) + '_' + str(step_mfcc) + '_' + str(hop_len) + '.hdf5'
                checkpoint = ModelCheckpoint(filepath=filename, monitor='val_loss', verbose=0, save_best_only=True)
                callbacks_list = [earlyStopping, checkpoint]
                model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])
                hist = model.fit(X, Y, epochs=100, batch_size=32, shuffle=True, validation_split = 0.2, verbose=1, callbacks=callbacks_list)
                model.summary()    
                print('accuracy:', max(hist.history['accuracy']))
                print('val_accuracy:', max(hist.history['val_accuracy']))
                plt.plot(hist.history['accuracy'])
                plt.plot(hist.history['val_accuracy'])
                plt.title('model accuracy')
                plt.ylabel('accuracy')
                plt.xlabel('epoch')
                plt.legend(['train', 'val'], loc='upper left')
                plt.show()
                print('loss:', min(hist.history['loss']));
                print('val_loss:', min(hist.history['val_loss']))
                plt.plot(hist.history['loss'])
                plt.plot(hist.history['val_loss'])
                plt.title('model loss')
                plt.ylabel('loss')
                plt.xlabel('epoch')
                plt.legend(['train', 'val'], loc='upper left')
                plt.show()
                print("Total training time:", (time.time()-t)/60)
                print("-----------------------------")
                print("-----------------------------")
                print("-----------------------------")
                print("-----------------------------\n\n\n")

"""**Train CNN**"""

# Train and store dense NN with different parameters
def train_dense(dir_train_file, dir_model_save):    
    t = time.time()        
    train_files = file_name(dir_train_file)    
    for f in [16000]:
        for hop_len in [256.0, 512.0, 1024.0, 2048.0]:
            window_time = hop_len/f
            print(window_time)
            if window_time < 0.05 or window_time > 0.4:
                print('Skip:', f, hop_len, window_time)
                continue
            print('FREQ:',  f, hop_len)            
            t = time.time()                       
            X, Y = generateDatasets(train_files, True, 1, 1, hop_len=hop_len, freq=f,dir = dir_train_file, model="CNN")            
            rand = np.random.permutation(np.arange(len(Y)))
            X = X[rand]
            Y = Y[rand]
            X = X - np.mean(X, axis=0)                    
            if X.shape[1] == 0:
                print("NEXT\n")
                continue
            input_shape = (X.shape[1], 1)
            model = model_dense(input_shape)
            model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])
            earlyStopping = EarlyStopping(monitor='val_loss', min_delta=0.00001, verbose=0, mode='min', patience=15)
            filename = dir_model_save + '/model_CNN_' + str(f) + '_' + str(1) + '_' + str(1) + '_' + str(hop_len) + '.hdf5'
            checkpoint = ModelCheckpoint(filepath=filename, monitor='val_loss', verbose=0, save_best_only=True)
            callbacks_list = [earlyStopping, checkpoint]
            hist = model.fit(X, Y, epochs=100, batch_size=32, shuffle=True, validation_split=0.2, verbose=0, callbacks=callbacks_list)
            model.summary()    
            print('accuracy:', max(hist.history['accuracy']))
            print('val_accuracy:', max(hist.history['val_accuracy']))
            plt.plot(hist.history['accuracy'])
            plt.plot(hist.history['val_accuracy'])
            plt.title('model accuracy')
            plt.ylabel('accuracy')
            plt.xlabel('epoch')
            plt.legend(['train', 'val'], loc='upper left')
            plt.show()
            print('loss:', min(hist.history['loss']));
            print('val_loss:', min(hist.history['val_loss']))
            plt.plot(hist.history['loss'])
            plt.plot(hist.history['val_loss'])
            plt.title('model loss')
            plt.ylabel('loss')
            plt.xlabel('epoch')
            plt.legend(['train', 'val'], loc='upper left')
            plt.show()
            print("Total training time:", (time.time()-t)/60)
            print("-----------------------------")
            print("-----------------------------")
            print("-----------------------------")
            print("-----------------------------\n\n\n")

"""**Train with store file pickle**"""

def train_with_store_file(model,model_type):
    t = time.time()
    nn = model
    step_sample = 0.05    # Space between the beginingof each sample  
    pickle_dir = TRAIN_STORE_DIR + model_type + '/'
    pickle_files = os.listdir(pickle_dir)
    pickle_files = [f for f in pickle_files if f.startswith('dataset')]
    for pickle_file in pickle_files:
      print(pickle_dir + pickle_file)
      with open(pickle_dir + pickle_file, 'rb') as f:
          results = pickle.load(f)
      params = pickle_file.replace('dataset_CUT_','').split('.pickle')[0].split('_')
      params = [ float(p) for p in params ]
      if model_type=="RNN":
        freq,hop_len, len_mfcc, step_mfcc, shape0, shape1,shape2 = params
      if model_type=="CNN":
        freq,hop_len, len_mfcc, step_mfcc, shape0, shape1 = params
      X=results[0]
      Y=results[1]
      rand = np.random.permutation(np.arange(len(Y)))
      X = X[rand]
      Y = Y[rand]
      if model_type=="RNN":
        X = np.array([ np.rot90(val) for val in X ])
      X = X - np.mean(X, axis=0)
      print('\nTrain data shape: ', X.shape,'\nNumber of label 0: ', len(Y[Y==0]),'\nNumber of label 1:', len(Y[Y==1]), float(len(Y[Y==0]))/len(Y[Y==1]))     
      if X.shape[1] == 0:
          print("NEXT\n")
          continue
      if model_type=="RNN":
        input_shape = (X.shape[1], X.shape[2]) 
      if model_type=="CNN":
        input_shape = (X.shape[1], 1)
      model = nn(input_shape)
      model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])
      earlyStopping = EarlyStopping(monitor='val_loss', min_delta=0.00001, verbose=0, mode='min', patience=5)
      filename = MODEL_STORE + model_type + '/model_'+ model_type + '_' + str(freq) + '_' + str(len_mfcc) + '_' + str(step_mfcc) + '_' + str(hop_len) + '.hdf5'
      checkpoint = ModelCheckpoint(filepath=filename, monitor='val_loss', verbose=0, save_best_only=True)
      callbacks_list = [earlyStopping, checkpoint]
      hist = model.fit(X, Y, epochs=25, batch_size=32, shuffle=True, validation_split=0.2, verbose=0, callbacks=callbacks_list)
      model.summary()    
      print('accuracy:', max(hist.history['accuracy']));
      print('val_accuracy:', max(hist.history['val_accuracy']));
      plt.plot(hist.history['accuracy'])
      plt.plot(hist.history['val_accuracy'])
      plt.title('model accuracy')
      plt.ylabel('accuracy')
      plt.xlabel('epoch')
      plt.legend(['train', 'val'], loc='upper left')
      plt.show()
      print('loss:', min(hist.history['loss']));
      print('val_loss:', min(hist.history['val_loss']))
      plt.plot(hist.history['loss'])
      plt.plot(hist.history['val_loss'])
      plt.title('model loss')
      plt.ylabel('loss')
      plt.xlabel('epoch')
      plt.legend(['train', 'val'], loc='upper left')
      plt.show()
      print("Total training time:", (time.time()-t)/60)
      print("-----------------------------")
      print("-----------------------------")
      print("-----------------------------")
      print("-----------------------------\n\n\n")

"""**Test result and return result**"""

def testResult(model,type,dir_test_file,dir_model,dir_srt):
    nn = model
    divide_and_conquer = True
    files = os.listdir(dir_model)
    files = [ f for f in files if f.startswith("model")]
    test_files = file_name(dir_test_file)
    results = []   
    for f in files:        
        params = f.replace('model_' + type + '_', '').split('.hdf5')[0].split('_')
        params = [ float(p) for p in params ]       
        freq, len_mfcc, step_mfcc, hop_len = params
        # if freq != 16000: continue
        # if hop_len != 512: continue
        # if freq >= 24000.0 or [freq,hop_len] in [ [q['freq'], q['hop_len']] for q in results ]:
        #     print("Skip:", freq, hop_len)
        #     continue        
        d = {}
        d['freq'] = freq
        d['len_mfcc'] = len_mfcc
        d['step_mfcc'] = step_mfcc
        d['hop_len'] = hop_len
        d['window_time'] = hop_len/freq
        item_time = hop_len/freq
        print('\n\n................................................')
        print('................................................')
        print(f)
        print('................................................')
        print('................................................\n')   
        print(params, hop_len/freq)
# =========================================Độ Chính xác của mô hình=================================================
        X, Y = [], []             
        for tf in test_files:
            train_data, labels = generateSingleDataset(tf, cut_data=False, len_mfcc=len_mfcc, step_mfcc=step_mfcc, hop_len=hop_len,dir = dir_test_file, freq=freq,verbose=0)
            X.append(train_data)
            Y.append(labels)
        X = np.concatenate(X)
        Y = np.concatenate(Y) 
        if type=="RNN":
          X = np.array([ np.rot90(val) for val in X ])
        X = X - np.mean(X, axis=0)
        # Load model save
        model = load_model(dir_model + f)
        preds = model.predict(X)
        preds= preds.round()
        # Original labels
        cm2  = confusion_matrix(Y, preds)
        plt.figure()
        plot_confusion_matrix(cm2,figsize=(12,8), hide_ticks=True ,cmap=plt.cm.cool)
        plt.xticks(range(2), ['0', '1'], fontsize=16)
        plt.yticks(range(2), ['0', '1'], fontsize=16)
        plt.show()
        tn, fp, fn, tp = cm2.ravel()
        precision = tp/(tp+fp)
        recall = tp/(tp+fn)
        f1_score = 2*((precision*recall)/(precision+recall))
        #đánh giá độ chính xác mô hình test
        loss, acc = model.evaluate(X, Y, verbose=2)
        d['accuracy'] = acc
        print("Test accuracy: ",acc)
        print("Precision of the model is: {:.3f}".format(precision))
        print("Recall of the model is: {:.3f}".format(recall))
        print("F1 score of the model is: {:.3f}".format(f1_score))
# ==========================================Xuất file phụ đề dự đoán=====================================================
        for tf in test_files:
          i = 0
          train_data, labels = generateSingleDataset(tf, cut_data=False, len_mfcc=len_mfcc, step_mfcc=step_mfcc, hop_len=hop_len,dir=dir_test_file, freq=freq,verbose=0)
          if type=="RNN":
            train_data = np.array([ np.rot90(val) for val in train_data ])
          train_data = train_data - np.mean(train_data, axis=0)
          # Load model save
          model = load_model(dir_model + f)
          preds = model.predict(train_data)
          preds= preds.round()
          txt = open(dir_srt+ f + '_'+ tf + '.txt', 'w')
          # Số mẫu nhãn 1 liên tiếp thấp nhất phải có để nhận định là tiếng người, 1 từ = 250ms          
          numberCell = math.floor(0.25/(item_time))
          for position, item in enumerate(preds):
            if item == 0: 
              i = 0
              continue
            if preds[position-1] == 0: 
              start = secToTime(posToTime(position, step_mfcc, freq, hop_len))
              pos_start = position
            if i < numberCell: 
              i += 1
              continue  
            if preds[position+1] == 0 and position != pos_start:
              txt.write(start)
              txt.write(" --> ")
              txt.write(secToTime(posToTime(position, step_mfcc, freq, hop_len)) + '\n')
              i = 0
          txt.close()         
# ==========================================Đồng bộ hóa phụ đề=====================================================
        for tf in test_files:                  
            t = time.time()            
            t_aux = time.time()
            X, Y = generateSingleDataset(tf, cut_data=False, len_mfcc=len_mfcc, step_mfcc=step_mfcc, hop_len=hop_len,dir=dir_test_file, freq=freq)
            if type=="RNN":
              X = np.array([ np.rot90(val) for val in X ])
            X = X - np.mean(X, axis=0)
            d[tf + '_time_load_dataset'] = (time.time()-t_aux)/60
            d[tf + '_Xshape'] = X.shape
            model = load_model(dir_model + f)
            t_aux = time.time()
            #Tạo mảng dự đoán xác suất đầu ra cho các mẫu đầu vào.
            preds = model.predict(X) 
            d[tf + '_time_predictions'] = (time.time()-t_aux)/60
            #load sub file
            subs = pysrt.open(dir_test_file + tf+'.srt')
            start_time = subs[0].start  
            start = timeToSec(subs[0].start)
            #Dời tất cả thời gian sub sớm hơn khoảng thời gian start
            subs.shift(seconds=-start)           
            t_aux = time.time()
            #Tạo mảng phụ đề mask
            mask = np.zeros(timeToPos(subs[len(subs)-1].end, step_mfcc, freq, hop_len)+1)
            print("Synchronizing")
            for sub in subs:
                for i in np.arange(timeToPos(sub.start, step_mfcc, freq, hop_len), timeToPos(sub.end, step_mfcc, freq, hop_len)+1):
                    if i<len(mask):
                        mask[i] = 1        
            if not divide_and_conquer:
                mtrs = []
                t_aux = time.time()
                for i in np.arange(0, (len(preds)-len(mask))):
                    if i % 1000 == 0: 
                        print("i:",i,"len_preds-len_mask:", (len(preds)-len(mask)), (time.time()-t_aux)/60)
                        t_aux = time.time()
#                       sklearn.metrics.log_loss(y_true, y_pred)
#                       lấy mảng phụ đề làm cửa sổ được di chuyển dọc theo mảng xác suất để tìm vị trí tốt nhất mà phụ đề 
#                       khớp với các ô có khả năng tìm thấy giọng người cao
                    mtrs.append(metrics.log_loss(mask, preds[i:i+len(mask)]))                  
                pos_to_delay = mtrs.index(min(mtrs))              
            else:
                mtrs_aux = []
                step_len = 50
                second_step_len = 500
                t_aux = time.time()
                for i in np.arange(0, (len(preds)-len(mask)), step_len):
                    if i % 1000 == 0: 
#                       print(i, (len(preds)-len(mask)), (time.time()-t_aux)/60)
                        t_aux = time.time()
                    mtrs_aux.append(metrics.log_loss(mask, preds[i:i+len(mask)]))                    
                min_index = mtrs_aux.index(min(mtrs_aux))*step_len
                plt.figure(figsize=(10,6))
                plt.plot(mtrs_aux) 
                plt.xlabel('Steps to delay', fontsize=18)
                plt.ylabel('Log Loss value', fontsize=18)
                plt.show()
                print('Best_mtr_aux_index:', min_index) 
                print("\nMin loss mtrs_aux:", min(mtrs_aux))  
# =============================================== Đồng bộ hóa phụ đề ===============================================            
                mtrs = []
                for i in np.arange(min_index-second_step_len, min_index+second_step_len):
                    if i<0 or i>=(len(preds)-len(mask)): continue
                    mtrs.append(metrics.log_loss(mask, preds[i:i+len(mask)]))
                pos_to_delay = mtrs.index(min(mtrs))            
            print("Synchronized")
            
            secsToDelay = posToTime(pos_to_delay, step_mfcc, freq, hop_len)
            subs.shift(seconds = secsToDelay)

            d[tf + '_time_sync'] = (time.time()-t_aux)/60
            plt.figure(figsize=(10,6))
            plt.plot(mtrs) 
            plt.xlabel('Steps to delay', fontsize=18)
            plt.ylabel('Log Loss value', fontsize=18)
            plt.show()
            print("\nMin loss mtrs:", min(mtrs))
            print("\nVị trí xuất hiện phụ đề start_time trong file srt:",timeToPos(start_time, step_mfcc, freq, hop_len))
            print("\nSec to pos:", secToPos(start, step_mfcc, freq, hop_len))
            print("\nVị trí xuất hiện phụ đề pos_to_delay sau khi dự đoán:", pos_to_delay)
            print("\nThời gian start_time trong file sub: ",start)
            print("\nThời gian start_time dự đoán:",secsToDelay)
            d[tf+'_loss'] = min(mtrs)
            d[tf+'_shift'] = [start, secsToDelay]
            total_elapsed_time = (time.time()-t)
            d[tf + '_time'] = (time.time()-t)/60
            print('Load: {0:.2f}, Preds: {0:.2f}, Sync: {0:.2f}'.format(d[tf + '_time_load_dataset'], d[tf + '_time_predictions'], d[tf + '_time_sync']))
            print(' - Time elapsed: {0:02d}:{1:02d}'.format(int(total_elapsed_time/60), int(total_elapsed_time % 60)))
            results.append(d)
    return results

"""**Store Result**"""

def storeResults(results, dir, model_type):
    with open(dir + model_type + '_results.pickle', 'wb') as f:
        pickle.dump(results, f)

"""**Eval Result**"""

# Plot stored training statistics. Look for the best model
def evalResults(pickle_dir,file_dir, model_type):

    pickle_files = os.listdir(pickle_dir)
    pickle_files = [f for f in pickle_files if f.startswith(model_type)]
    for pickle_file in pickle_files:
      print(pickle_dir + pickle_file)

      with open(pickle_dir + pickle_file, 'rb') as f:
          results = pickle.load(f)
          print(results)
          files = file_name(file_dir)
          for f in files:
            vals = [d[f+"_loss"] for d in results ]
            fig, ax = plt.subplots(figsize=(35,5))
            plt.plot(vals)
            ax.set_xticks(np.arange(0, len(vals)))
            ax.set_xticklabels([ str(d['freq'])+'_'+str(d['hop_len'])+'_'+str(d['len_mfcc']) for d in results ], rotation=20)
            plt.show()    
            # Metrics to plot
            colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']
            
            width = 0.15
                
            freqs = sorted(list(set([ d['freq'] for d in results ])))
            hop_lens = sorted(list(set([ d['hop_len'] for d in results ])))
            pos = list(np.arange(len(hop_lens)))
            m = f+'_loss'
                
            # Plot metrics
            fig, ax = plt.subplots()
            for i in np.arange(len(freqs)):
                vals = { d['hop_len']:d[m] for d in results if d['freq']==freqs[i] }
                print(vals)
                vals.update({ hl:0.0 for hl in hop_lens if hl not in vals.keys() })
                vals = collections.OrderedDict(sorted(vals.items()))
                plt.bar([p + width*i for p in pos],[ v for k,v in vals.items() ],width,alpha=0.5,color=colors[i])

            ax.set_ylabel('Value')
            ax.set_xticks([p + 1.5 * width for p in pos])
            ax.set_xticklabels(hop_lens, rotation=20)
            plt.xlim(min(pos)-width, max(pos)+width*4)
        #    plt.legend(freqs, loc=1)
            ax.legend(freqs, loc='center left', bbox_to_anchor=(1, 0.75))
            plt.show()            
            res = [ d for d in results if d['window_time']<=0.3 ]            
            # Metrics to plot
            colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']            
            width = 0.12
            freqs = sorted(list(set([ d['freq'] for d in res ])))
            hop_lens = sorted(list(set([ d['hop_len'] for d in res ])))
            pos = list(np.arange(len(freqs)))
                
            # Plot metrics
            fig, ax = plt.subplots(figsize=(8,4))
            for i in np.arange(len(hop_lens)):
                # vals = { d['freq']: d[str(f) + '_loss'] for d in res if d['hop_len']==hop_lens[i] }
                vals = { d['freq']: d[str(f) + '_time'] for d in res if d['hop_len']==hop_lens[i] }
                # print(vals)
                # print(hop_lens[i], { hl:0.0 for hl in freqs if hl not in vals.keys() })
                vals.update({ hl:0.003 for hl in freqs if hl not in vals.keys() })
                vals = collections.OrderedDict(sorted(vals.items()))
                print(hop_lens[i], vals)

                plt.bar([p + width*i for p in pos],[ v for k,v in vals.items() ],width,alpha=0.5,color=colors[i])
            ax.set_ylabel('Value time')
            ax.set_xticks([p + 3 * width for p in pos])
            ax.set_xticklabels(freqs, rotation=20)
            plt.xlim(min(pos)-width, max(pos)+width*len(hop_lens) + width)
            ax.legend(hop_lens, loc='center left', bbox_to_anchor=(1, 0.75))
            plt.show()

"""**Call the function**"""

#-----------------------------RNN------------------------------
#train_lstm(TRAIN1_DATA_DIR,RNN1_MODEL_STORE)
#train_with_store_file(model_lstm,"RNN")
testResult(model_lstm,"RNN",TEST1_DATA_DIR,RNN1_MODEL_STORE,RESULT1_DIR)
#storeResults(testResult(model_lstm,"RNN",TEST1_DATA_DIR,RNN1_MODEL_STORE,RESULT1_DIR),RESULT1_DIR,"RNN")
#-----------------------------CNN------------------------------
#train_dense(TRAIN1_DATA_DIR,CNN1_MODEL_STORE)
#train_with_store_file(model_dense,"CNN")
testResult(model_dense,"CNN",TEST1_DATA_DIR,CNN1_MODEL_STORE,RESULT1_DIR)
#storeResults(testResult(model_dense,"CNN",TEST1_DATA_DIR,CNN1_MODEL_STORE,RESULT1_DIR),RESULT1_DIR,"CNN")

from google.colab import drive
drive.mount('/content/drive')